version: '3.8'

services:
  frontend:
    build: 
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      - API_BASE_URL=http://backend:8000
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on:
      - backend
    restart: unless-stopped

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      # Core Platform Configuration
      - DATABASE_URL=postgresql://postgres:password@db:5432/docextract
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      
      # Application Settings
      - DEBUG=true
      - MAX_FILE_SIZE=52428800  # 50MB
      
      # Security
      - TENANT_SECRET_ENCRYPTION_KEY=dev-tenant-secret-encryption-key-change-in-production
      
      # External Service Endpoints (tenant-agnostic)
      - MINIO_ENDPOINT_URL=http://minio:9000
      - OLLAMA_ENDPOINT_URL=http://ollama:11434
      
      # Global Defaults (can be overridden per tenant)
      - DEFAULT_AWS_REGION=us-east-1
      - DEFAULT_OLLAMA_MODEL=gemma2:2b
      - DEFAULT_OPENAI_MODEL=gpt-4
      - DEFAULT_OPENAI_MAX_TOKENS=2000
      - DEFAULT_OPENAI_TEMPERATURE=0.3
    volumes:
      - ./backend:/app
    depends_on:
      - db
      - redis
      - minio
      - ollama
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  celery-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    command: celery -A src.celery_app worker --loglevel=info --queues=celery,high_priority,normal_priority,low_priority,scheduled
    environment:
      # Core Platform Configuration
      - DATABASE_URL=postgresql://postgres:password@db:5432/docextract
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      
      # Application Settings
      - DEBUG=true
      - MAX_FILE_SIZE=52428800  # 50MB
      
      # Security
      - TENANT_SECRET_ENCRYPTION_KEY=dev-tenant-secret-encryption-key-change-in-production
      
      # External Service Endpoints (tenant-agnostic)
      - MINIO_ENDPOINT_URL=http://minio:9000
      - OLLAMA_ENDPOINT_URL=http://ollama:11434
      
      # Global Defaults (can be overridden per tenant)
      - DEFAULT_AWS_REGION=us-east-1
      - DEFAULT_OLLAMA_MODEL=gemma2:2b
      - DEFAULT_OPENAI_MODEL=gpt-4
      - DEFAULT_OPENAI_MAX_TOKENS=2000
      - DEFAULT_OPENAI_TEMPERATURE=0.3
    volumes:
      - ./backend:/app
    depends_on:
      - db
      - redis
      - minio
      - ollama
    restart: unless-stopped

  celery-beat:
    build:
      context: ./backend
      dockerfile: Dockerfile
    command: celery -A src.celery_app beat --loglevel=info
    environment:
      # Core Platform Configuration
      - DATABASE_URL=postgresql://postgres:password@db:5432/docextract
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      
      # Application Settings
      - DEBUG=true
      - MAX_FILE_SIZE=52428800  # 50MB
      
      # Security
      - TENANT_SECRET_ENCRYPTION_KEY=dev-tenant-secret-encryption-key-change-in-production
      
      # External Service Endpoints (tenant-agnostic)
      - MINIO_ENDPOINT_URL=http://minio:9000
      - OLLAMA_ENDPOINT_URL=http://ollama:11434
      
      # Global Defaults (can be overridden per tenant)
      - DEFAULT_AWS_REGION=us-east-1
      - DEFAULT_OLLAMA_MODEL=gemma2:2b
      - DEFAULT_OPENAI_MODEL=gpt-4
      - DEFAULT_OPENAI_MAX_TOKENS=2000
      - DEFAULT_OPENAI_TEMPERATURE=0.3
    volumes:
      - ./backend:/app
    depends_on:
      - db
      - redis
    restart: unless-stopped

  db:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=docextract
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/01-init.sql
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d docextract"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  minio:
    image: minio/minio:latest
    ports:
      - "9000:9000"   # S3 API
      - "9001:9001"   # MinIO Console UI
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    restart: unless-stopped

  # MinIO initialization (creates default buckets for development)
  minio-init:
    image: minio/mc:latest
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      echo 'Waiting for MinIO to be ready...';
      sleep 10;
      /usr/bin/mc alias set myminio http://minio:9000 minioadmin minioadmin;
      echo 'MinIO connection established';
      echo 'Note: Tenant-specific buckets will be created automatically via the application';
      echo 'MinIO setup completed';
      "
    restart: "no"

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 6G
    # Uncomment for GPU support
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  # Ollama model initialization
  ollama-init:
    image: curlimages/curl:latest
    depends_on:
      ollama:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      echo 'Waiting for Ollama to be ready...';
      sleep 15;
      echo 'Pulling Gemma 3 4B model...';
      curl -X POST http://ollama:11434/api/pull -d '{\"name\":\"gemma3:4b\"}' || echo 'Model pull failed, will retry during backend startup';
      echo 'Ollama setup completed';
      "
    restart: "no"

volumes:
  postgres_data:
    driver: local
  minio_data:
    driver: local
  ollama_data:
    driver: local
  redis_data:
    driver: local

networks:
  default:
    driver: bridge
